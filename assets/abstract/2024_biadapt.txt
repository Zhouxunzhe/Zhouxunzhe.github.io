Bimanual manipulation tasks, such as opening a box or using scissors, are prevalent in daily life. These tasks require policies that account for collaboration, leading to a high demand for extensive training data. When manipulating novel, unseen categories of objects in a bi-manual manner, the significant variation in geometric characteristics and physical properties across object categories further complicates generalization. To address these challenges, we introduce Bi-Adapt, a novel framework for learning bi-manual manipulation of novel categories. By leveraging semantic correspondence from foundation models with exceptional generalization capabilities, Bi-Adapt transfers manipulation affordances to novel categories. Additionally, it proposes efficient few-shot adaptations using minimal data to fine-tune the transferred policy, ensuring robust performance in collaborative tasks. Our experiments show that Bi-Adapt achieves a high success rate in cross-category bi-manual manipulation tasks, demonstrating its ability to generalize efficiently through few-shot learning.