<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Xunzhe Zhou's Homepage</title>
    <meta name="author" content="Xunzhe Zhou">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="css/stylesheet.css">
    <style>
      body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        /* background-color: #f4f4f4; */
      }
      .name {
        text-align: center;
        font-size: xx-large;
        margin-bottom: 0;
      }
      table {
        width: 100%;
        max-width: 800px;
        border: 0;
        border-spacing: 0;
        border-collapse: separate;
        margin: auto;
      }
      td {
        padding: 2.5%;
      }
      img {
        width: 100%;
        max-width: 100%;
        object-fit: cover;
      }
      .hoverZoomLink {
        transition: transform 0.2s;
      }
      .hoverZoomLink:hover {
        transform: scale(1.04);
      }
      a {
        color: #007BFF;
        text-decoration: none;
      }
      a:hover {
        text-decoration: underline;
      }
      .news, .research, .publications, .projects {
        padding: 14px;
      }
      .footer {
        font-size: small;
        margin-top: 20px;
      }
    </style>
  </head>
  <body>
    <table>
      <tr>
        <td>
          <table>
            <tr>
              <td style="width: 60%; vertical-align: middle;">
                <p class="name">Xunzhe Zhou</p>
                <p>
                  I am an undergraduate student at <a href="https://www.fudan.edu.cn/en/">Fudan University</a>, pursuing my Bachelor's degree in Computer Science and Technology.
                </p>
                <p>
                  Recently, I have been working with Prof. <a href="https://linsats.github.io/">Lin Shao</a> on embodied task planning. Previously, I collaborated with Prof. <a href="https://faculty.fudan.edu.cn/xyxue/zh_CN/index.htm">Xiangyang Xue</a> and Prof. <a href="https://yanweifu.github.io/">Yanwei Fu</a> on research involving embodied spatial perception and planning. I also worked with Prof. <a href="http://kw.fudan.edu.cn/people/xiaoyanghua/">Yanghua Xiao</a> on studying LLMs' instruction following capabilities, and with Prof. <a href="https://faculty.fudan.edu.cn/syleng/zh_CN/index.htm">Siyang Leng</a> on nonlinear dynamical systems control.
                </p>
                <p>
                  I also had a wonderful semester at the <a href="https://www.berkeley.edu/">UC Berkeley</a> during fall 2023, where I studied reinforcement learning, deep learning, optimization models, and artificial intelligence, with GPA 4.00 / 4.00.
                </p>
                <p style="text-align:center">
                  <a href="mailto:xunzhe_zhou@outlook.com">Email</a> &nbsp;/&nbsp;
                  <a href="./assets/files/CV_202407.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://github.com/Zhouxunzhe">GitHub</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=IEi7AToAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/xunzhe-zhou/">LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://twitter.com/ZHOUxzhe">Twitter</a>
                </p>
              </td>
              <td style="width: 40%; max-width: 40%;">
                <a href="assets/img/profile.jpg">
                  <img alt="profile photo" src="assets/img/profile.jpg" style="width:100%;max-width:100%;object-fit: cover; border-radius: 60%;" class="hoverZoomLink">
                </a>
              </td>
            </tr>
          </table>

          <div class="news">
            <h2>News</h2>
            <p>[Dec. 2023] Our paper <strong>CELLO</strong> is accepted by AAAI 2024!</p>
          </div>

          <div class="research">
            <h2>Research</h2>
            <p>
              My ultimate goal is to achieve fully automated general embodied intelligence systems. 
            </p>
            <p>
              My current research interests focus on leveraging existing foundational models to assist robots in the physical world with perception and decision-making. Specifically, 1) I aim to develop a general perception system to understand complex and dynamic environments; 2) I seek to create a decision-making systems for autonomous long-term task planning.
            </p>
            <p>
              In the future, I plan to continue my research work by 1) developing a universal learning system for heterogeneous robots to learn unified skills, 2) creating a data collection system in various tasks and different scenarios, and 3) building a multi-robot collaboration system to enhance overall efficiency and learning capabilities.
            </p>
          </div>

          <div class="publications">
            <h2>Publications</h2>
            <p>
              <!-- Representative papers are <span class="highlight">highlighted</span>.  -->
              * denotes equal contribution.
            </p>
            <table>
              <tr>
                <td style="width: 30%; vertical-align: middle;">
                  <img src="assets/img/2024_rc.png" alt="RC" width="200">
                </td>
                <td style="width: 70%; vertical-align: middle;">
                  <a><strong><span class="papertitle">Reservoir computing as digital twins for controlling nonlinear dynamical systems</span></strong></a><br>
                  R. Cao*, <strong>Xunzhe Zhou*</strong>, J. Hou, C. Guan, S. Leng<br>
                  <em>In submission</em>, 2024<br>
                  <!-- <a href="assets/abstract/2024_rc.txt">abstract</a> -->
                  <p>We validate the effectiveness of our digital twins in replicating unknown complex systems and further demonstrate how to select and implement appropriate control strategies based on the specific requirements.</p>
                </td>
              </tr>
              <!-- <tr bgcolor="#ffffd0"> -->
              <tr>
                <td style="width: 30%; vertical-align: middle;">
                  <img src="./assets/img/2023_cello.png" alt="CELLO" width="200">
                </td>
                <td style="width: 70%; vertical-align: middle;">
                  <a><strong><span class="papertitle">Can Large Language Models Understand Real-World Complex Instructions?</span></strong></a><br>
                  Q. He, J. Zeng, W. Huang, L. Chen, J. Xiao, Q. He, <strong>Xunzhe Zhou</strong>, L. Chen, X. Wang, Y. Huang, H. Ye, Z. Li, S. Chen, Y. Zhang, Z. Gu, J. Liang, Y. Xiao<br>
                  <em>AAAI</em>, 2024<br>
                  <a href="https://abbey4799.github.io/publication/cello/">project page</a> / <a href="assets/abstract/2023_cello.txt">abstract</a> / <a href="https://arxiv.org/abs/2309.09150">paper</a> / <a href="https://github.com/Abbey4799/CELLO">code</a> / <a href="assets/bibtex/2023_cello.bib">bibtex</a> / <a href="https://underline.io/lecture/92662-can-large-language-models-understand-real-world-complex-instructionsquestion">video</a>
                  <p>We propose CELLO, a benchmark for evaluating LLMs' ability to follow complex instructions. We design eight features for complex instructions and construct a comprehensive evaluation dataset from real-world scenarios. We also establish four criteria and corresponding metrics.</p>
                </td>
              </tr>
            </table>
          </div>

          <div class="projects">
            <h2>Selected Projects</h2>
            <table>
              <tr>
                <td style="width: 30%; vertical-align: middle;">
                  <img src="assets/img/2023_nst.png" alt="NST" width="200">
                </td>
                <td style="width: 70%; vertical-align: middle;">
                  <a><strong><span class="papertitle">Neural Style Transfer Based on Fine Tuning Vision Transformer</span></strong></a><br>
                  <em>UC Berkeley CS182/282A course project</em>, 2023<br>
                  <a href="https://github.com/Zhouxunzhe/NST-NeuralStyleTransfer">project page</a> / <a href="assets/files/NST.pdf">essay</a> / <a href="https://github.com/Zhouxunzhe/NST-NeuralStyleTransfer">code</a>
                  <p>Inspired by StyTr<sup>2</sup>, we replace its content and style encoders with pretrained ViT models. We propose a two-stage training strategy and wrap the ViTs with LoRA for joint training.</p>
                </td>
              </tr>
            </table>
          </div>

          <div class="footer">
            <p style="text-align: center">Design and source code from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron's website</a>.</p>
          </div>
        </td>
      </tr>
    </table>
  </body>
</html>
